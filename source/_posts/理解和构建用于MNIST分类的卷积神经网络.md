---
title: "ç†è§£å’Œæ„å»ºç”¨äºMNISTåˆ†ç±»çš„å·ç§¯ç¥ç»ç½‘ç»œ"
date: 2024-04-23T10:56:17+08:00
categories: ["AI"]
tags: [AI]
---
åœ¨æ·±åº¦å­¦ä¹ é¢†åŸŸï¼Œæ„å»ºç¥ç»ç½‘ç»œæ¥è§£å†³å„ç§ä»»åŠ¡æ˜¯ä¸€é¡¹ä»¤äººå…´å¥‹çš„å·¥ä½œã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†æ·±å…¥æ¢è®¨ä½¿ç”¨PyTorchæ„å»ºå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰å¯¹æ¥è‡ªæµè¡Œçš„MNISTæ•°æ®é›†çš„æ‰‹å†™æ•°å­—è¿›è¡Œåˆ†ç±»ã€‚

## 1ã€å¯¼å…¥åº“å’ŒåŠ è½½æ•°æ®

é¦–å…ˆï¼Œè®©æˆ‘ä»¬é€šè¿‡å¯¼å…¥å¿…è¦çš„åº“å’ŒåŠ è½½MNISTæ•°æ®é›†æ¥è®¾ç½®æˆ‘ä»¬çš„ç¯å¢ƒã€‚PyTorchå’Œtorchvisionå¯¹äºå¤„ç†æ•°æ®å’Œåˆ›å»ºç¥ç»ç½‘ç»œè‡³å…³é‡è¦ï¼Œè€Œmatplotlibåˆ™æœ‰åŠ©äºå¯è§†åŒ–å›¾åƒã€‚

```python
import numpy as np
import torch
from torchvision import datasets, transforms
import matplotlib.pyplot as plt
import torchvision
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
```

ç°åœ¨ï¼Œè®©æˆ‘ä»¬åŠ è½½æ•°æ®é›†ã€‚æˆ‘ä»¬å°†å¯¹æ•°æ®è¿›è¡Œå½’ä¸€åŒ–å¤„ç†ï¼Œä»¥ä½¿å…¶å‡å€¼ä¸ºé›¶ï¼Œæ–¹å·®ä¸º1ï¼Œä»¥ç¡®ä¿è®­ç»ƒç¨³å®šæ€§ã€‚

```python
train_loader = torch.utils.data.DataLoader(
    datasets.MNIST(root='./data',
                   train=True,
                   download=True,
                   transform=transforms.Compose([
                       transforms.ToTensor(),
                       transforms.Normalize((0.1307,), (0.3081,))
                   ])),
    batch_size=64, shuffle=True)
test_loader = torch.utils.data.DataLoader(
    datasets.MNIST('./data', train=False, transform=transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.1307,), (0.3081,))
    ])),
    batch_size=64, shuffle=True)
```

## 2ã€æ•°æ®å¯è§†åŒ–

åœ¨æ·±å…¥ç½‘ç»œæ¶æ„ä¹‹å‰ï¼Œè®©æˆ‘ä»¬å…ˆå·å·çœ‹ä¸€ä¸‹æˆ‘ä»¬çš„æ•°æ®ã€‚å¯è§†åŒ–ä¸€äº›æ ·æœ¬å›¾åƒå¯ä»¥å¸®åŠ©æˆ‘ä»¬äº†è§£æ•°æ®é›†çš„ç‰¹å¾ã€‚

```python
def imshow(img):
    img = img / 2 + 0.5  # åå½’ä¸€åŒ–
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()

dataiter = iter(train_loader)
images, labels = dataiter.next()
imshow(torchvision.utils.make_grid(images))
```

## 3ã€å®šä¹‰ç¥ç»ç½‘ç»œæ¶æ„

ç°åœ¨æ˜¯æ ¸å¿ƒéƒ¨åˆ† - å®šä¹‰æˆ‘ä»¬çš„CNNæ¶æ„ã€‚æˆ‘ä»¬å°†ä¸ºæ•°å­—åˆ†ç±»åˆ›å»ºä¸€ä¸ªç®€å•è€Œæœ‰æ•ˆçš„ç½‘ç»œã€‚

```python
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 6, 5)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16 * 4 * 4, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x):
        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))
        x = F.max_pool2d(F.relu(self.conv2(x)), 2)
        x = x.view(-1, self.num_flat_features(x))
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x

    def num_flat_features(self, x):
        size = x.size()[1:]
        num_features = 1
        for s in size:
            num_features *= s
        return num_features

net = Net()
print(net)
```

## 4ã€å‰å‘ä¼ æ’­å’ŒæŸå¤±è®¡ç®—

åœ¨å®šä¹‰ç½‘ç»œåï¼Œè®©æˆ‘ä»¬çœ‹çœ‹å®ƒå¦‚ä½•å¤„ç†ä¸€æ‰¹è¾“å…¥å›¾åƒå¹¶è®¡ç®—æŸå¤±ã€‚

```python
image = images[:2]
label = labels[:2]
out = net(image)
criterion = nn.CrossEntropyLoss()
loss = criterion(out, label)
print(loss)
```

## 5ã€è®­ç»ƒæ¨¡å‹

ç°åœ¨æ˜¯è®­ç»ƒæ—¶é—´ï¼æˆ‘ä»¬å°†éå†æ•°æ®é›†å¤šä¸ªå‘¨æœŸï¼Œæ›´æ–°æ¨¡å‹å‚æ•°ä»¥æœ€å°åŒ–æŸå¤±ã€‚

```python
optimizer = optim.SGD(net.parameters(), lr=0.01)

def train(epoch):
    net.train()
    running_loss = 0.0
    for i, data in enumerate(train_loader):
        inputs, labels = data
        optimizer.zero_grad()
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()
        if i % 100 == 0:
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 100))
            running_loss = 0.0

train(1)
```

## 6ã€è¯„ä¼°æ¨¡å‹æ€§èƒ½

æœ€åï¼Œè®©æˆ‘ä»¬è¯„ä¼°æˆ‘ä»¬è®­ç»ƒå¥½çš„æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„è¡¨ç°å¦‚ä½•ã€‚

```python
correct = 0
total = 0
with torch.no_grad():
    for data in test_loader:
        images, labels = data
        outputs = net(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
print('ç½‘ç»œåœ¨10000ä¸ªæµ‹è¯•å›¾åƒä¸Šçš„å‡†ç¡®ç‡ä¸ºï¼š%d %%' % (100 * correct / total))
```
![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://img-blog.csdnimg.cn/direct/ed9e97a5617d4acb881ea30a43c35337.png)

é€šè¿‡è·Ÿéšè¿™äº›æ­¥éª¤ï¼Œæˆ‘ä»¬æˆåŠŸåœ°æ„å»ºå¹¶è®­ç»ƒäº†ä¸€ä¸ªç”¨äºMNISTæ•°å­—åˆ†ç±»çš„CNNï¼Œåœ¨æœªè§è¿‡çš„æ•°æ®ä¸Šå–å¾—äº†ä¸é”™çš„å‡†ç¡®ç‡ã€‚è¿™ä¸ºæ›´é«˜çº§çš„æ·±åº¦å­¦ä¹ å·¥ä½œå¥ å®šäº†åŸºç¡€ã€‚ç¥ç¼–ç æ„‰å¿«ï¼ ğŸš€

ä»¥ä¸‹æ˜¯å®Œæ•´çš„ä»£ç ï¼š

```python
import numpy as np
import torch
from torchvision import datasets, transforms
import matplotlib.pyplot as plt
import torchvision
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

# å¯¼å…¥æ•°æ®é›†
train_loader = torch.utils.data.DataLoader(
    datasets.MNIST(root='./data',
                   train=True,
                   download=True,
                   transform=transforms.Compose([
                       transforms.ToTensor(),
                       transforms.Normalize((0.1307,), (0.3081,))
                   ])),
    batch_size=64, shuffle=True)
test_loader = torch.utils.data.DataLoader(
    datasets.MNIST('./data', train=False, transform=transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.1307,), (0.3081,))
    ])),
    batch_size=64, shuffle=True)


def imshow(img):
    img = img / 2 + 0.5  # åå½’ä¸€åŒ–
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()


dataiter = iter(train_loader)
images, labels = dataiter.next()
imshow(torchvision.utils.make_grid(images))


# å®šä¹‰ç¥ç»ç½‘ç»œ
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 6, 5)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16 * 4 * 4, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x):
        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))
        x = F.max_pool2d(F.relu(self.conv2(x)), 2)
        x = x.view(-1, self.num_flat_features(x))
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x

    def num_flat_features(self, x):
        size = x.size()[1:]
        num_features = 1
        for s in size:
            num_features *= s
        return num_features


net = Net()
print(net)


# å‰å‘ä¼ æ’­
image = images[:2]
label = labels[:2]
out = net(image)
print(out)


# è®¡ç®—æŸå¤±
criterion = nn.CrossEntropyLoss()
loss = criterion(out, label)
print(loss)


# åå‘ä¼ æ’­ä¸æ›´æ–°å‚æ•°
optimizer = optim.SGD(net.parameters(), lr=0.01)
image = images[:2]
label = labels[:2]
optimizer.zero_grad()
out = net(image)
loss = criterion(out, label)
loss.backward()
optimizer.step()


# å¼€å§‹è®­ç»ƒ
def train(epoch):
    net.train()
    running_loss = 0.0
    for i, data in enumerate(train_loader):
        inputs, labels = data
        optimizer.zero_grad()
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()
        if i % 100 == 0:
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 100))
            running_loss = 0.0


train(1)


# è§‚å¯Ÿæ¨¡å‹é¢„æµ‹æ•ˆæœ
correct = 0
total = 0
with torch.no_grad():
    for data in test_loader:
        images, labels = data
        outputs = net(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
print('ç½‘ç»œåœ¨10000ä¸ªæµ‹è¯•å›¾åƒä¸Šçš„å‡†ç¡®ç‡ä¸ºï¼š%d %%' % (100 * correct / total))
```

è¿™æ®µä»£ç æ¶µç›–äº†ä»æ•°æ®åŠ è½½ã€æ„å»ºæ¨¡å‹ã€è®­ç»ƒåˆ°è¯„ä¼°çš„å®Œæ•´æµç¨‹ï¼Œä½¿ç”¨äº†PyTorchåº“è¿›è¡Œå®ç°ã€‚
